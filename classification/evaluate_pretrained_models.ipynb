{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "data_dir = '/scratch/es5223/medsynth/data_syntheticCT/TBX11K_orig_classification_splits/'\n",
    "TYPE='proj'\n",
    "TRIAL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import itertools\n",
    "import torchvision\n",
    "from util import *\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from apex import amp\n",
    "import seaborn as sns\n",
    "import albumentations\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import scikitplot as skplt\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from timm import create_model\n",
    "from datetime import datetime\n",
    "from timm.data.loader import *\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from cutmix.cutmix import CutMix\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "#from pytorch_metric_learning import loss\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from apex.parallel import convert_syncbn_model\n",
    "from timm.utils import ApexScaler, NativeScaler\n",
    "from cutmix.utils import CutMixCrossEntropyLoss\n",
    "from timm.models.registry import register_model\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from timm.models.resnet import resnet26d, resnet50d\n",
    "from torchvision import transforms, models, datasets\n",
    "from timm.models.helpers import build_model_with_cfg\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "from apex.parallel import DistributedDataParallel as ApexDDP\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.models.efficientnet import efficientnet_b0, efficientnet_b1, efficientnet_b2, efficientnet_b3\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score, roc_curve, auc, roc_auc_score\n",
    "#from timm.data import Dataset, DatasetTar, RealLabelsImagenet, create_loader, Mixup, FastCollateMixup, AugMixDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_joint(ct_path):\n",
    "    ct_array = np.load(ct_path)\n",
    "    tmp = ct_path.replace(data_dir,\n",
    "                    '/scratch/es5223/medsynth/data/TBX11K_classification_splits/')\n",
    "    tmp = tmp.replace('CT_','')\n",
    "    tmp = tmp.replace('.npy','.png')\n",
    "    if '.jpg.png' in tmp:\n",
    "        tmp = tmp.replace('.png','')\n",
    "    if not os.path.isfile(tmp):\n",
    "        tmp = tmp.replace('.png','.jpg')\n",
    "    if not os.path.isfile(tmp):\n",
    "        print('ct_path ', ct_path)\n",
    "        print('x_path ', tmp)\n",
    "\n",
    "    x_img = cv2.imread(tmp, cv2.IMREAD_GRAYSCALE) * 1/256.\n",
    "    x_image = cv2.resize(x_img,dsize=(224,224))\n",
    "    # c_img = cv2.resize(ct_array[63,:,:],dsize=(224,224))\n",
    "    # c_image = ct_array[32:96,:,:].transpose(2, 1, 0) #.convert('RGB')\n",
    "    c_image = ct_array[:,:,:].transpose(2, 1, 0) #.convert('RGB')\n",
    "    return [np.expand_dims(c_image, axis=0), np.expand_dims(x_image, axis=0)] #img_concat\n",
    "\n",
    "def is_valid_file(path):\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "batch_size = 10\n",
    "num_epochs = 500\n",
    "lr = 0.01\n",
    "beta = 1\n",
    "step_size = 130\n",
    "img_size_c = 128\n",
    "img_size = 224\n",
    "test_size = int((256 / 224) * img_size)\n",
    "\n",
    "mean = [0.485] \n",
    "std = [0.229]\n",
    "num_workers = 0\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms_x = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.Resize(224),\n",
    "        #transforms.ToTensor(),\n",
    "        transforms.Normalize(0., 1.),\n",
    "        transforms.RandomErasing()\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(224),\n",
    "        #transforms.ToTensor(),\n",
    "        transforms.Normalize(0., 1.)\n",
    "        #transforms.RandomErasing()\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        #transforms.Resize(224),\n",
    "        #transforms.ToTensor(),\n",
    "        transforms.Normalize(0., 1.)\n",
    "        #transforms.RandomErasing()\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "data_transforms_ct = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomRotation(30),\n",
    "        #transforms.Resize(img_size),\n",
    "        #transforms.ToTensor(),\n",
    "        transforms.Normalize(0., 1.),\n",
    "        #transforms.RandomErasing(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(img_size),\n",
    "        #transforms.ToTensor(),\n",
    "        transforms.Normalize(0., 1.),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        #transforms.Resize(img_size),\n",
    "        #transforms.ToTensor(),\n",
    "        transforms.Normalize(0., 1.),\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "print(\"data_dir \", data_dir)\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), \n",
    "                                          #data_transforms_ct[x],\n",
    "                                          loader=load_image_joint,\n",
    "                                          is_valid_file=is_valid_file) for x in ['train', 'val', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "num_classes = len(class_names)\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=num_workers, pin_memory = True)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['val'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['val']))\n",
    "print(\"len(images) \", len(images))\n",
    "print(\"images[0].shape \", images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(images) \", len(images))\n",
    "print(\"images[0].shape \", images[0].shape)\n",
    "\n",
    "ct_data = images[0]\n",
    "x_data = images[1]\n",
    "\n",
    "ct_data_transformed = data_transforms_ct['train'](ct_data)\n",
    "print(ct_data_transformed.shape)\n",
    "\n",
    "x_data_transformed = data_transforms_ct['train'](x_data)\n",
    "print(x_data_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [],
   "source": [
    "class CNN3D(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN3D, self).__init__()\n",
    "        \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxPool = torch.nn.MaxPool3d(kernel_size=2)\n",
    "\n",
    "\n",
    "        self.conv1 = torch.nn.Conv3d(1, 64, kernel_size=(3,3,3))\n",
    "        self.batchNorm1 = torch.nn.BatchNorm3d(num_features=64)\n",
    "\n",
    "\n",
    "        self.conv2 = torch.nn.Conv3d(64, 64, kernel_size=(3,3,3))\n",
    "        self.batchNorm2 = torch.nn.BatchNorm3d(num_features=64)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv3d(64, 128, kernel_size=(3,3,3))\n",
    "        self.batchNorm3 = torch.nn.BatchNorm3d(num_features=128)\n",
    "\n",
    "        self.conv4 = torch.nn.Conv3d(128, 256, kernel_size=(3,3,3))\n",
    "        self.batchNorm4 = torch.nn.BatchNorm3d(num_features=256)\n",
    "\n",
    "\n",
    "        self.avgPool = torch.nn.AvgPool3d(kernel_size=(6,6,6))\n",
    "        self.fc1 = torch.nn.Linear(256, 512)\n",
    "        self.dropout = torch.nn.Dropout3d(0.3)\n",
    "        #self.fc2 = torch.nn.Linear(512, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxPool(x)\n",
    "        x = self.batchNorm1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxPool(x)\n",
    "        x = self.batchNorm2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxPool(x)\n",
    "        x = self.batchNorm3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxPool(x)\n",
    "        x = self.batchNorm4(x)\n",
    "\n",
    "        x = self.avgPool(x).squeeze()\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)#.squeeze()\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ct = torch.randn((batch_size, 1, 128, 128, 128))\n",
    "data_x = torch.randn((batch_size, 1, 224, 224))\n",
    "\n",
    "output = model(data_ct, data_x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "#criterion = CutMixCrossEntropyLoss(True)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "#lr = lambda x: (((1 + math.cos(x * math.pi / num_epochs)) / 2) ** 1) * 0.9\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=5, after_scheduler=scheduler)\n",
    "#model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n",
    "#loss_scaler = ApexScaler()\n",
    "#show our model architechture and send to GPU\n",
    "model.to(device)\n",
    "model.model_x.to(device)\n",
    "model.model_ct.to(device)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/clovaai/CutMix-PyTorch\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create classifier\n",
    "# for param in model.model_x.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in model.model_ct.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# model_x.head.weight\n",
    "# model_x.head.bias\n",
    "# model_ct.fc2.weight\n",
    "# model_ct.fc2.bias\n",
    "# fc1.weight\n",
    "# fc1.bias\n",
    "\n",
    "\n",
    "params_to_optimize = list(model.model_x.head.parameters()) + list(model.model_ct.fc2.parameters()) + list(model.fc1.parameters())\n",
    "optimizer = optim.SGD(params_to_optimize, lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "#lr = lambda x: (((1 + math.cos(x * math.pi / num_epochs)) / 2) ** 1) * 0.9\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=5, after_scheduler=scheduler)\n",
    "\n",
    "# model.fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "data_transforms_ct_L = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomRotation(30),\n",
    "        #transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0., 1.),\n",
    "        #transforms.RandomErasing(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0., 1.),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        #transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0., 1.),\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "def load_image_joint_print(ct_path):\n",
    "    ct_array = np.load(ct_path)\n",
    "    tmp = ct_path.replace(data_dir,\n",
    "                    '/scratch/es5223/medsynth/data/TBX11K_classification_splits/')\n",
    "    tmp = tmp.replace('CT_','')\n",
    "    tmp = tmp.replace('.npy','.png')\n",
    "    if '.jpg.png' in tmp:\n",
    "        tmp = tmp.replace('.png','')\n",
    "    if not os.path.isfile(tmp):\n",
    "        tmp = tmp.replace('.png','.jpg')\n",
    "    if not os.path.isfile(tmp):\n",
    "        print('ct_path ', ct_path)\n",
    "        print('x_path ', tmp)\n",
    "\n",
    "    x_img = cv2.imread(tmp, cv2.IMREAD_GRAYSCALE) * 1/256.\n",
    "    x_image = cv2.resize(x_img,dsize=(224,224))\n",
    "    # c_img = cv2.resize(ct_array[63,:,:],dsize=(224,224))\n",
    "    # c_image = ct_array[32:96,:,:].transpose(2, 1, 0) #.convert('RGB')\n",
    "    c_image = ct_array[:,:,:].transpose(2, 1, 0) #.convert('RGB')\n",
    "    c_image_t = c_image #np.expand_dims(c_image, axis=0)\n",
    "    c_image_t = data_transforms_ct_L['test'](c_image_t)\n",
    "    return [c_image_t, np.expand_dims(x_image, axis=0)] #img_concat\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    Source: https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "    \n",
    "test_dataset = ImageFolderWithPaths(os.path.join(data_dir, 'test'), \n",
    "                                          #data_transforms_ct['test'],\n",
    "                                          loader=load_image_joint_print,\n",
    "                                          is_valid_file=is_valid_file)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4,\n",
    "                                             shuffle=False, num_workers=0, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load x model\n",
    "model_X_only = create_model('vit_small_patch16_224', pretrained=True, in_chans=1, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_validate_meterX(model, val_loader, CHECK_POINT_PATH): # best_model_path,\n",
    "    since = time.time()\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "        print(\"checkpoint loaded\")\n",
    "    except:\n",
    "        checkpoint = None\n",
    "        print(\"checkpoint not found\")\n",
    "\n",
    "    def load_model(best_model_path):                                \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "        \n",
    "    device = torch.device(\"cuda:0\")\n",
    "    load_model(CHECK_POINT_PATH)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_y = list()\n",
    "    test_y = list()\n",
    "    probas_y = list()\n",
    "    with torch.no_grad():\n",
    "        for data, target,paths in val_loader:\n",
    "            #print(\"data[0].shape \", data[0].shape)\n",
    "            #print(\"data[1].shape \", data[1].shape)\n",
    "            #print(\"target.shape \", target.shape)\n",
    "            #data, target = data[0].to(device), target.to(device)\n",
    "            target = target.to(device)\n",
    "            #ct_data = data[0]\n",
    "            x_data = data[1]\n",
    "\n",
    "            #ct_data_transformed = data_transforms_ct[phase](ct_data)\n",
    "            x_data_transformed = data_transforms_x['test'](x_data)\n",
    "\n",
    "            #ct_data_transformed = ct_data_transformed.float().to(device)\n",
    "            x_data_transformed = x_data_transformed.float().to(device)\n",
    "                    \n",
    "            data, target = Variable(x_data_transformed), Variable(target)\n",
    "            output = model(data.float())\n",
    "            probas_y.extend(output.data.cpu().numpy().tolist())\n",
    "            pred_y.extend(output.data.cpu().max(1, keepdim=True)[1].numpy().flatten().tolist())\n",
    "            test_y.extend(target.data.cpu().numpy().flatten().tolist())\n",
    "        # compute the confusion matrix\n",
    "        confusion = confusion_matrix(test_y, pred_y)\n",
    "        # plot the confusion matrix\n",
    "        plot_labels = ['HEALTH', 'SICK', 'TB']\n",
    "        #plot_confusion_matrix(confusion, plot_labels)\n",
    "        #plot_confusion_matrix(confusion, classes=val_loader.dataset.classes,title='Confusion matrix')\n",
    "        # print Recall, Precision, F1-score, Accuracy\n",
    "        report = classification_report(test_y, pred_y, digits=4)\n",
    "        print(report)\n",
    "        #plt_roc(test_y, probas_y)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Inference completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return test_y, pred_y\n",
    "\n",
    "test_y_X, pred_y_X = compute_validate_meterX(model_X_only, test_data_loader, 'models_trials/X_orig_VT_TRIAL_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_X0, pred_y_X0 = compute_validate_meterX(model_X_only, test_data_loader, 'models_trials/X_orig_VT_TRIAL_0.pth')\n",
    "test_y_X1, pred_y_X1 = compute_validate_meterX(model_X_only, test_data_loader, 'models_trials/X_orig_VT_TRIAL_1.pth')\n",
    "test_y_X2, pred_y_X2 = compute_validate_meterX(model_X_only, test_data_loader, 'models_trials/X_orig_VT_TRIAL_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get CT only results\n",
    "from model_cnn import CNN3D\n",
    "\n",
    "# load ct model\n",
    "model_CT_only = CNN3D(num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dir)\n",
    "\n",
    "def load_image(path):\n",
    "    ct_array = np.load(path)\n",
    "    # image = Image.fromarray(ct_array[63,:,:])#.convert('RGB')\n",
    "    image = ct_array[:,:,:].transpose(2, 1, 0) #.convert('RGB')\n",
    "    return image\n",
    "\n",
    "def is_valid_file(path):\n",
    "    return True\n",
    "\n",
    "def compute_validate_meterCT(model, val_loader, CHECK_POINT_PATH): # best_model_path,\n",
    "    since = time.time()\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "        print(\"checkpoint loaded\")\n",
    "    except:\n",
    "        checkpoint = None\n",
    "        print(\"checkpoint not found\")\n",
    "\n",
    "    def load_model(best_model_path):                                \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "        \n",
    "    device = torch.device(\"cuda:0\")\n",
    "    load_model(CHECK_POINT_PATH)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_y = list()\n",
    "    test_y = list()\n",
    "    probas_y = list()\n",
    "    with torch.no_grad():\n",
    "        for data, target,paths in val_loader:\n",
    "            target_orig = target\n",
    "            target = torch.nn.functional.one_hot(target, num_classes=3)\n",
    "            target = target.float()\n",
    "            target = target.to(device)\n",
    "            ct_data = data[0].unsqueeze(1)\n",
    "\n",
    "            #ct_data_transformed = data_transforms_ct['test'](ct_data)\n",
    "            #@ct_data_transformed = ct_data_transformed.float().to(device)\n",
    "            data = ct_data#ct_data_transformed\n",
    "            data=data.to(device)\n",
    "#         for data, target in val_loader:\n",
    "#             # print(\"paths \", paths)\n",
    "#             target_orig = target\n",
    "#             target = torch.nn.functional.one_hot(target, num_classes=3)\n",
    "#             target = target.float()\n",
    "            \n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "            output = model(data)\n",
    "            probas_y.extend(output.data.cpu().numpy().tolist())\n",
    "            pred_y.extend(output.data.cpu().max(1, keepdim=True)[1].numpy().flatten().tolist())\n",
    "            test_y.extend(target_orig.data.cpu().numpy().flatten().tolist())\n",
    "            \n",
    "        # compute the confusion matrix\n",
    "        confusion = confusion_matrix(test_y, pred_y)\n",
    "        # plot the confusion matrix\n",
    "        plot_labels = ['HEALTH', 'SICK', 'TB']\n",
    "        #plot_confusion_matrix(confusion, plot_labels)\n",
    "        #plot_confusion_matrix(confusion, classes=val_loader.dataset.classes,title='Confusion matrix')\n",
    "        # print Recall, Precision, F1-score, Accuracy\n",
    "        report = classification_report(test_y, pred_y, digits=4)\n",
    "        print(report)\n",
    "        #plt_roc(test_y, probas_y)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Inference completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return test_y, pred_y\n",
    "test_y_CT, pred_y_CT = compute_validate_meterCT(model_CT_only, test_data_loader, 'models_trials/3D_CNN_bce_allSlice+proj0.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_CT0, pred_y_CT0 = compute_validate_meterCT(model_CT_only, test_data_loader, 'models_trials/3D_CNN_bce_allSlice+proj0.pth')\n",
    "test_y_CT1, pred_y_CT1 = compute_validate_meterCT(model_CT_only, test_data_loader, 'models_trials/3D_CNN_bce_allSlice+proj1.pth')\n",
    "test_y_CT2, pred_y_CT2 = compute_validate_meterCT(model_CT_only, test_data_loader, 'models_trials/3D_CNN_bce_allSlice+proj2.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
